#!/usr/bin/python2.7
# -*- coding: utf-8 -*-
"""
PIh5.py: Deal with the proton imaging particle tracks found optionally in HDF5 files of >FLASH4.4

Created by Scott Feister on Wed Apr 19 19:07:25 2017
"""

import h5py
import numpy as np
import os
import scipy.signal
#import matplotlib.pyplot as plt

# TODO: Add a "shuffle=True" as default, that shuffles the particles
def readh5(fn, overwrite=False, shuffle=True):
    """ Read the protons out of the PI plotfile 
    fn: full filepath to the HDF5 plotfile generated by FLASH itself
    overwrite: If true, create or overwrite the '*_PItracks.h5' file. If false (default), check to see if the modified output hdf5 file already exists, and return that if it does
    shuffle: If True, shuffle the order of particles in the list. If false, sort by order of ID number.
    """

    # Define output tracks filename
    folder, name_in = os.path.split(fn)
    name_out = os.path.splitext(name_in)[0] + '_PItracks.h5' # Output filename sans directory
    fn_out = os.path.join(folder, name_out) # Output filename with directory
    
    if not overwrite:
        if os.path.isfile(fn_out):
            print(r"Reading trakarr from secondary '*_PItracks.h5' file...")
            with h5py.File(fn_out, 'r') as f:
                trakarr = f['trakarr'][...]
                return trakarr
    
    print("Creating secondary '*_PItracks.h5' file")
    ## Load into working memory and sort by particle ID
    print("Loading HDF5 plotfile tracks into memory...")
    with h5py.File(fn, 'r') as f:
        dat = f["ProtonData"][...]
    
    print("Sorting tracks by particle ID...")
    ix_arr = np.argsort(dat[:,0], kind='mergesort') # Sort by particle ID # (index 0). Mergesort keeps the paths in order, for a given ID # # TODO: Sort in batch sizes?
    dat = dat[ix_arr, :] # Sorted array
    
    # Split into sub-arrays / tracks
    # http://stackoverflow.com/questions/19125661/find-index-where-elements-change-value-numpy
    print("Splitting tracks...")
    idarr = dat[:, 0] # Array of particle ID numbers
    splitix = np.where(idarr[:-1] != idarr[1:])[0] + 1 # Array of indices at which particle ID changes (split here)
    edgeix = np.hstack((0, splitix, len(idarr))) # Array of start and stop indices; N + 1 long, where N is number of particle tracks
    traklens = np.diff(edgeix) # Array of particle track lengths
    ntraks = len(traklens) # Number of particle tracks
    
    ## Split into a larger array with one more dimension
    tlmax = np.max(traklens)  # Max track length (number of steps); Either the max number in the arrays, or 50 steps
    trakarr = np.empty((ntraks, tlmax, dat.shape[1]))
    trakarr.fill(np.nan)
    
    for i in range(ntraks):
        trakarr[i,:min(traklens[i], tlmax),:] = dat[edgeix[i]:edgeix[i] + min(traklens[i], tlmax),:]

    if shuffle:
        print("Shuffling particle track order...")
        np.random.shuffle(trakarr) # Re-order particles randomly

    # Write your new tracks to file
    print("Writing tracks to new HDF5 file in the same folder...")    
    with h5py.File(fn_out, 'w') as f:
        f.create_dataset('trakarr', data=trakarr)
        f.create_dataset('traklens', data=traklens)
        f.create_dataset('idarr', data=idarr)

    return trakarr


def moreinfo(trakarr):
    """ Digests output of "readh5"; Returns a breakdown of particle path lengths, deflection angles, positions, velocities, and accelerations
    
    Given N particles are stored in the HDF5 file:
    Inputs:
        trakarr   NumPy array, N x step x 4, full specification of trajectories; the output of "readh5" function above
    Outputs:
        pathl     NumPy array, N x step, cumulative path length along the particle trajectory
        theta     NumPy array, N x step, particle angle relative to Z axis along trajectory
        posxyz    NumPy array, 3 x N x step, particle position along trajectory
        velxyz    NumPy array, 3 x N x step, particle velocity along trajectory
        accxyz    NumPy array, 3 x N x step, particle acceleration along trajectory
        
    """
    
    dtrakarr = np.diff(trakarr, axis=1) # Difference along the traveling axis
    dr = np.sqrt(dtrakarr[:,:,1]**2 + dtrakarr[:,:,2]**2 + dtrakarr[:,:,3]**2) # N x Steps-1 long, Path length change between steps
    pathl = np.concatenate((np.zeros((dr.shape[0],1)), np.cumsum(dr, axis=1)), axis=1) # N x Steps long, Total path length up to this step

    posxyz = np.rollaxis(trakarr[:,:,1:],2,0) # Positions along the trajectory (Component x Particle x Step#)
    velxyz = np.gradient(posxyz, axis=2) # Non-normalized velocities along the trajectories (Component x Particle x Step#)
    velxyz = velxyz / np.sqrt(np.sum(velxyz**2, axis=0)) # Normalized velocities along the trajectories, normalized to 1 (Component x Particle x Step#)

    velmag = np.sqrt(np.sum(velxyz**2, axis=0)) # This is actually always 1, in our case
    theta = np.arccos(velxyz[1]/velmag)
    
    accxyz = np.gradient(velxyz, axis=2) # Accelerations, using a normalized velocity
    accmag = np.sqrt(np.sum(accxyz**2, axis=0)) # Magnitude of acceleration, using the normalized velocity
    
    return pathl, theta, posxyz, velxyz, accxyz

if __name__ == "__main__":
    pass