#!/usr/bin/python2.7
# -*- coding: utf-8 -*-
"""
PIh5.py: Deal with the proton imaging particle tracks found optionally in HDF5 files of >FLASH4.4

Created by Scott Feister on Wed Apr 19 19:07:25 2017
"""

import h5py
import numpy as np
import os

def bustmypi(fn):
    """ Read the protons out of the PI plotfile 
    fn: full filepath to the HDF5 plotfile generated by FLASH
    """
    
    ## Load into working memory and sort by particle ID
    print("Loading HDF5 plotfile tracks into memory...")
    with h5py.File(fn, 'r') as f:
        dat = f["ProtonData"][...]
    
    print("Sorting tracks by particle ID...")
    ix_arr = np.argsort(dat[:,0], kind='mergesort') # Sort by particle ID # (index 0). Mergesort keeps the paths in order, for a given ID # # TODO: Sort in batch sizes?
    dat = dat[ix_arr, :] # Sorted array
    
    # Split into sub-arrays / tracks
    # http://stackoverflow.com/questions/19125661/find-index-where-elements-change-value-numpy
    print("Splitting tracks...")
    idarr = dat[:, 0] # Array of particle ID numbers
    splitix = np.where(idarr[:-1] != idarr[1:])[0] + 1 # Array of indices at which particle ID changes (split here)
    edgeix = np.hstack((0, splitix, len(idarr))) # Array of start and stop indices; N + 1 long, where N is number of particle tracks
    traklens = np.diff(edgeix) # Array of particle track lengths
    ntraks = len(traklens) # Number of particle tracks
    
    ## Split into a larger array with one more dimension
    tlmax = np.max(traklens)  # Max track length (number of steps); Either the max number in the arrays, or 50 steps
    trakarr = np.empty((ntraks, tlmax, dat.shape[1]))
    trakarr.fill(np.nan)
    
    for i in range(ntraks):
        trakarr[i,:min(traklens[i], tlmax),:] = dat[edgeix[i]:edgeix[i] + min(traklens[i], tlmax),:]

    # Write your new tracks to file
    print("Writing sorted tracks to new HDF5 file in the same folder...")
    folder, name_in = os.path.split(fn)
    name_out = os.path.splitext(name_in)[0] + '_PItracks.hdf5' # Output filename sans directory
    fn_out = os.path.join(folder, name_out) # Output filename with directory
    
    with h5py.File(fn_out, 'w') as f:
        f.create_dataset('trakarr', data=trakarr)
        
        
def mytest():        
    dtrakarr = np.diff(trakarr, axis=1) # Difference along the traveling axis
    dr = np.sqrt(dtrakarr[:,:,1]**2 + dtrakarr[:,:,2]**2 + dtrakarr[:,:,3]**2) # N x Steps-1 long, Path length change between steps
    pathl = np.concatenate((np.zeros((dr.shape[0],1)), np.cumsum(dr, axis=1)), axis=1) # N x Steps long, Total path length up to this step

    posxyz = np.rollaxis(trakarr[:,:,1:],2,0) # Positions along the trajectory (Component x Particle x Step#)
    velxyz = np.gradient(posxyz, axis=2) # Non-normalized velocities along the trajectories (Component x Particle x Step#)
    velxyz = velxyz / np.sqrt(np.sum(velxyz**2, axis=0)) # Normalized velocities along the trajectories, normalized to 1 (Component x Particle x Step#)

    velmag = np.sqrt(np.sum(velxyz**2, axis=0)) # This is actually always 1, in our case
    theta = np.arccos(velxyz[1]/velmag)
    
    accxyz = np.gradient(velxyz, axis=2) # Accelerations, using a normalized velocity
    accmag = np.sqrt(np.sum(accxyz**2, axis=0)) # Magnitude of acceleration, using the normalized velocity
    
                    
if __name__ == "__main__":
    pltfn = r"C:\Users\Scott\Documents\temp\subdata.hdf5"
    bustmypi(pltfn)

